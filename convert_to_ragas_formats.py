#!/usr/bin/env python3
"""
åˆ›å»ºä¸¤ç§Ragasè¯„ä¼°æ ¼å¼çš„æ•°æ®é›†
æ–¹æ¡ˆ1: ä½¿ç”¨AIå›ç­”åˆ—ä½œä¸ºanswer
æ–¹æ¡ˆ2: è®©Ragasè‡ªå·±ç”Ÿæˆç­”æ¡ˆ
"""

import pandas as pd
import json
import re
from typing import List, Dict
import sys

def extract_contexts_from_contexts_column(contexts_text: str) -> List[str]:
    """ä»Contextsåˆ—ä¸­æå–chunkå†…å®¹ä½œä¸ºcontextsåˆ—è¡¨"""
    if pd.isna(contexts_text) or not contexts_text:
        return ["æ— å‚è€ƒæ–‡æ¡£"]
    
    contexts = []
    contexts_text = str(contexts_text).strip()
    
    # æŒ‰æ–‡ä»¶æ ‡é¢˜åˆ†å‰²chunks: [æ–‡ä»¶å]: å†…å®¹
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–‡ä»¶æ ‡é¢˜æ ¼å¼
    chunk_pattern = r'\[([^\]]+\.\w+)\]:\s*\n([^[]*?)(?=\n\[[^\]]+\.\w+\]:|$)'
    matches = re.findall(chunk_pattern, contexts_text, re.DOTALL)
    
    if matches:
        for filename, content in matches:
            # æ¸…ç†å†…å®¹ï¼šå»æ‰å¤šä½™ç©ºç™½å’Œæ¢è¡Œ
            cleaned_content = re.sub(r'\s+', ' ', content.strip())
            if cleaned_content:
                contexts.append(cleaned_content)
    else:
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ ‡å‡†æ ¼å¼ï¼Œå°è¯•æŒ‰åŒæ¢è¡Œåˆ†å‰²
        chunks = contexts_text.split('\n\n')
        for chunk in chunks:
            chunk = chunk.strip()
            if chunk and len(chunk) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                # ç§»é™¤å¯èƒ½çš„æ–‡ä»¶æ ‡é¢˜æ ‡è®°
                chunk = re.sub(r'^\[.*?\]:\s*', '', chunk)
                contexts.append(chunk)
    
    return contexts if contexts else ["å‚è€ƒæ–‡æ¡£ä¿¡æ¯ä¸æ˜ç¡®"]

def extract_contexts_from_reference(reference_text: str) -> List[str]:
    """ä»å‚è€ƒæ–‡æ¡£ä¸­æå–çœŸå®çš„contexts"""
    if pd.isna(reference_text) or not reference_text:
        return ["æ— å‚è€ƒæ–‡æ¡£"]
    
    contexts = []
    
    # æå–æ–‡æ¡£åç§°ï¼ˆç›¸å…³åº¦æœ€é«˜çš„å‰3ä¸ªï¼‰
    doc_pattern = r'- (.+?\.(?:xlsx|doc|pdf)) \(ç›¸å…³åº¦: ([\d.]+)\)'
    matches = re.findall(doc_pattern, reference_text)
    
    if matches:
        # æŒ‰ç›¸å…³åº¦æ’åºï¼Œå–å‰3ä¸ª
        sorted_matches = sorted(matches, key=lambda x: float(x[1]), reverse=True)[:3]
        for doc, score in sorted_matches:
            contexts.append(f"æ¥æºæ–‡æ¡£: {doc}")
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£ä¿¡æ¯ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬çš„å‰å‡ è¡Œ
    if not contexts:
        lines = reference_text.strip().split('\n')
        contexts = [line.strip() for line in lines[:2] if line.strip() and 'ç›¸å…³åº¦' not in line][:3]
    
    return contexts if contexts else ["å‚è€ƒæ–‡æ¡£ä¿¡æ¯ä¸æ˜ç¡®"]

def clean_ai_answer(ai_answer: str) -> str:
    """æ¸…ç†AIå›ç­”ï¼Œåˆ é™¤å›¾ç‰‡é“¾æ¥ä½†ä¿ç•™æ–‡å­—å†…å®¹"""
    if pd.isna(ai_answer) or not ai_answer:
        return ""
    
    ai_answer = str(ai_answer).strip()
    
    # åˆ é™¤å›¾ç‰‡ç›¸å…³çš„æ ‡ç­¾å’Œé“¾æ¥ï¼Œä½†ä¿ç•™å…¶ä»–æ–‡å­—å†…å®¹
    # 1. åˆ é™¤<img>æ ‡ç­¾
    ai_answer = re.sub(r'<img[^>]*>', '', ai_answer, flags=re.IGNORECASE | re.DOTALL)
    
    # 2. åˆ é™¤"ç›¸å…³å›¾ç‰‡"æ®µè½ï¼ˆåŒ…æ‹¬å„ç§å¯èƒ½çš„æ ¼å¼ï¼‰
    # åŒ¹é… "\n\nç›¸å…³å›¾ç‰‡xxx\n\n" çš„æ®µè½
    ai_answer = re.sub(r'\n\n\s*ç›¸å…³å›¾ç‰‡[^.\n]*?\s*\n\n', '\n\n', ai_answer, flags=re.IGNORECASE)
    # åŒ¹é…ç»“å°¾çš„ç›¸å…³å›¾ç‰‡æ®µè½
    ai_answer = re.sub(r'\n\n\s*ç›¸å…³å›¾ç‰‡[^.\n]*?\s*$', '', ai_answer, flags=re.IGNORECASE)
    # åŒ¹é…å•ç‹¬ä¸€è¡Œçš„ç›¸å…³å›¾ç‰‡
    ai_answer = re.sub(r'\n\s*ç›¸å…³å›¾ç‰‡[^.\n]*?\s*\n', '\n', ai_answer, flags=re.IGNORECASE)
    # åŒ¹é…è¡Œæœ«çš„ç›¸å…³å›¾ç‰‡
    ai_answer = re.sub(r'ç›¸å…³å›¾ç‰‡[^.\n]*?$', '', ai_answer, flags=re.IGNORECASE | re.MULTILINE)
    
    # 3. æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
    ai_answer = re.sub(r'\n\s*\n\s*\n', '\n\n', ai_answer)
    
    # 4. æ¸…ç†é¦–å°¾ç©ºç™½
    ai_answer = ai_answer.strip()
    
    return ai_answer

def create_format1_ai_answer(excel_path: str, output_path: str) -> None:
    """
    æ–¹æ¡ˆ1: ä½¿ç”¨AIå›ç­”åˆ—ä½œä¸ºanswer
    - question: é—®é¢˜
    - answer: AIå›ç­”åˆ—çš„å†…å®¹ï¼ˆè¢«è¯„ä¼°çš„å›ç­”ï¼‰
    - contexts: Contextsåˆ—ä¸­çš„chunkå†…å®¹ï¼ˆä½œä¸ºå‚è€ƒä¸Šä¸‹æ–‡ï¼‰
    - ground_truth: æ ‡å‡†ç­”æ¡ˆï¼ˆè¯„ä¼°åŸºå‡†ï¼‰
    """
    
    print("ğŸ”„ åˆ›å»ºæ–¹æ¡ˆ1: AIå›ç­”ä½œä¸ºanswerï¼ŒContextsåˆ—ä½œä¸ºcontexts...")
    df = pd.read_excel(excel_path)
    
    ragas_data = []
    
    for idx, row in df.iterrows():
        # è·³è¿‡æ²¡æœ‰å¿…è¦å­—æ®µçš„è¡Œ
        if pd.isna(row['é—®é¢˜']) or pd.isna(row['æ ‡å‡†ç­”æ¡ˆ']) or pd.isna(row['AIå›ç­”']):
            continue
        
        # ä»Contextsåˆ—æå–chunkå†…å®¹ä½œä¸ºcontexts
        if 'Contexts' in row and not pd.isna(row['Contexts']):
            contexts = extract_contexts_from_contexts_column(row['Contexts'])
        else:
            # å¦‚æœæ²¡æœ‰Contextsåˆ—ï¼Œå›é€€åˆ°ä½¿ç”¨æ ‡å‡†ç­”æ¡ˆ
            standard_answer = str(row['æ ‡å‡†ç­”æ¡ˆ']).strip()
            if len(standard_answer) > 200:
                # é•¿ç­”æ¡ˆåˆ†æ®µä½œä¸ºå¤šä¸ªcontexts
                segments = re.split(r'[ï¼›;ã€‚]', standard_answer)
                contexts = [seg.strip() for seg in segments[:3] if seg.strip()]
            else:
                contexts = [standard_answer]
        
        # æ¸…ç†AIå›ç­”ï¼Œåˆ é™¤å›¾ç‰‡ç›¸å…³å†…å®¹åé¢çš„éƒ¨åˆ†
        cleaned_ai_answer = clean_ai_answer(row['AIå›ç­”'])
        
        item = {
            "question": str(row['é—®é¢˜']).strip(),
            "answer": cleaned_ai_answer,  # æ¸…ç†åçš„AIå›ç­”
            "contexts": contexts,  # Contextsåˆ—çš„chunkå†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡
            "ground_truth": str(row['æ ‡å‡†ç­”æ¡ˆ']).strip(),  # æ ‡å‡†ç­”æ¡ˆ
        }
        
        ragas_data.append(item)
    
    # ä¿å­˜æ•°æ®
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(ragas_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ–¹æ¡ˆ1å®Œæˆï¼Œå…± {len(ragas_data)} æ¡æ•°æ®")
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_path}")
    
    # æ˜¾ç¤ºæ ·ä¾‹
    if ragas_data:
        sample = ragas_data[0]
        print(f"\nğŸ“ æ–¹æ¡ˆ1æ ·ä¾‹:")
        print(f"é—®é¢˜: {sample['question'][:30]}...")
        print(f"AIå›ç­”: {sample['answer'][:50]}...")
        print(f"æ ‡å‡†ç­”æ¡ˆ: {sample['ground_truth'][:50]}...")
        print(f"Contextsæ•°é‡: {len(sample['contexts'])}")
        print(f"Contextsç¤ºä¾‹: {sample['contexts'][0][:100] if sample['contexts'] else 'æ— '}...")

def create_format2_empty_answer(excel_path: str, output_path: str) -> None:
    """
    æ–¹æ¡ˆ2: è®©Ragasè‡ªå·±ç”Ÿæˆç­”æ¡ˆ
    - question: é—®é¢˜
    - answer: ç©ºå­—ç¬¦ä¸²ï¼ˆè®©Ragasçš„LLMç”Ÿæˆï¼‰
    - contexts: Contextsåˆ—ä¸­çš„chunkå†…å®¹ï¼ˆä½œä¸ºå‚è€ƒä¸Šä¸‹æ–‡ï¼‰
    - ground_truth: æ ‡å‡†ç­”æ¡ˆï¼ˆè¯„ä¼°åŸºå‡†ï¼‰
    """
    
    print("ğŸ”„ åˆ›å»ºæ–¹æ¡ˆ2: è®©Ragasç”Ÿæˆç­”æ¡ˆï¼ŒContextsåˆ—ä½œä¸ºcontexts...")
    df = pd.read_excel(excel_path)
    
    ragas_data = []
    
    for idx, row in df.iterrows():
        if pd.isna(row['é—®é¢˜']) or pd.isna(row['æ ‡å‡†ç­”æ¡ˆ']):
            continue
        
        # ä»Contextsåˆ—æå–chunkå†…å®¹ä½œä¸ºcontexts
        if 'Contexts' in row and not pd.isna(row['Contexts']):
            contexts = extract_contexts_from_contexts_column(row['Contexts'])
        else:
            # å¦‚æœæ²¡æœ‰Contextsåˆ—ï¼Œå›é€€åˆ°ä½¿ç”¨æ ‡å‡†ç­”æ¡ˆ
            standard_answer = str(row['æ ‡å‡†ç­”æ¡ˆ']).strip()
            if len(standard_answer) > 200:
                # é•¿ç­”æ¡ˆåˆ†æ®µä½œä¸ºå¤šä¸ªcontexts
                segments = re.split(r'[ï¼›;ã€‚]', standard_answer)
                contexts = [seg.strip() for seg in segments[:3] if seg.strip()]
            else:
                contexts = [standard_answer]
        
        item = {
            "question": str(row['é—®é¢˜']).strip(),
            "answer": "",  # ç©ºç­”æ¡ˆï¼Œè®©Ragasç”Ÿæˆ
            "contexts": contexts,  # Contextsåˆ—çš„chunkå†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡
            "ground_truth": str(row['æ ‡å‡†ç­”æ¡ˆ']).strip(),  # æ ‡å‡†ç­”æ¡ˆ
        }
        
        ragas_data.append(item)
    
    # ä¿å­˜æ•°æ®
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(ragas_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ–¹æ¡ˆ2å®Œæˆï¼Œå…± {len(ragas_data)} æ¡æ•°æ®")
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_path}")
    
    # æ˜¾ç¤ºæ ·ä¾‹
    if ragas_data:
        sample = ragas_data[0]
        print(f"\nğŸ“ æ–¹æ¡ˆ2æ ·ä¾‹:")
        print(f"é—®é¢˜: {sample['question'][:30]}...")
        print(f"AIå›ç­”: [ç©ºï¼Œå¾…ç”Ÿæˆ]")
        print(f"æ ‡å‡†ç­”æ¡ˆ: {sample['ground_truth'][:50]}...")
        print(f"Contextsæ•°é‡: {len(sample['contexts'])}")
        print(f"Contextsç¤ºä¾‹: {sample['contexts'][0][:100] if sample['contexts'] else 'æ— '}...")

def main():
    excel_file = sys.argv[1]
    
    # æ–¹æ¡ˆ1: è¯„ä¼°ç°æœ‰AIå›ç­”
    format1_output = sys.argv[2]
    create_format1_ai_answer(excel_file, format1_output)
    
    # print("\n" + "="*60 + "\n")
    
    # # æ–¹æ¡ˆ2: è®©Ragas LLMç”Ÿæˆæ–°å›ç­”
    # format2_output = sys.argv[2]
    # create_format2_empty_answer(excel_file, format2_output)
    
    # print(f"\nğŸ¯ ä¸¤ç§æ ¼å¼éƒ½å·²åˆ›å»ºå®Œæˆ!")
    # print(f"ğŸ“ è¯„ä¼°ç°æœ‰AIå›ç­”: {format1_output}")
    # print(f"ğŸ“ è¯„ä¼°LLMç”Ÿæˆå›ç­”: {format2_output}")

if __name__ == "__main__":
    main()